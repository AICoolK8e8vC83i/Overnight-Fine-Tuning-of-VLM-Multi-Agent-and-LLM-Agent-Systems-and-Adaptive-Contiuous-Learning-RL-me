Submitting a preprint to ARXiv ViGRL-Align: Visual Grounded Reinforcement Learning with Language Feedback for Embodied AI Safety. 

Intro: Embodied AI + alignment problem
Related work: RL from human feedback, visual grounding, embodied AI
Method: Architecture (vision encoder â†’ RL policy + language feedback module)
Results: Learning curves, ablation (with/without language feedback)
Discussion: Implications for AI safety, future work

Focusing on Avoiding Next Token Prediction Simplicity (e.g. User wants to OPtimize for X Goal --> Next token for X Goal) and considering real world nuances, context, consequences, and chain of thought alignemnt reasoning to consider the user's other goals not just the one presented in the context window

Goal: Finish SOTA for Momentum, slacking off AI E2E projects and learning.
Goal: Accuracy metrics
Goal: This is for sure done (no excuses, no "aghh let's change project scope)
Goal: Publish to ArXiv preprint before 2026 so maybe chance of conference?? 
